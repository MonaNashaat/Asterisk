{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asterisk\n",
    "\n",
    "We propose Asterisk, a framework to generate high-quality training datasets at scale. Instead of relying on the end users to write user-defined heuristics, the proposed approach exploits a small set of labeled data and automatically produces a set of heuristics to assign initial labels. In this phase, the system applies an iterative process of creating, testing, and ranking heuristics in each, and every, iteration to only accommodate high-quality heuristics. Then, Asterisk examines the disagreements between these heuristics to model their accuracies. In order to enhance the quality of the generated labels, the framework improves the accuracies of the heuristics by applying a novel data-driven AL process. During the process, the system examines the generated weak labels along with the modeled accuracies of the heuristics to help the learner decide on the points for which the user should provide true labels. The process aims at enhancing the accuracy, and the coverage of the training data while engaging the user in the loop to execute the enhancement process. Therefore, by incorporating the underlying data representation, the user is only queried about the points that are expected to enhance the overall labeling quality. Then, the true labels provided by the users are used to refine the initial labels generated by the heuristics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T02:34:02.347553Z",
     "start_time": "2019-01-29T02:34:02.274196Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "try:\n",
    "    import heuristics_generator\n",
    "except ImportError:\n",
    "    print(ImportError)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T22:16:18.073016Z",
     "start_time": "2019-01-28T22:16:18.055597Z"
    }
   },
   "source": [
    "Reading and preparing the data from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T22:16:18.795193Z",
     "start_time": "2019-01-28T22:16:18.773099Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from heuristics_generator.hg_utils import *\n",
    "DU= read_data(\"rain_prediction.csv\", 'RainTomorrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T22:16:19.807190Z",
     "start_time": "2019-01-28T22:16:19.784177Z"
    }
   },
   "outputs": [],
   "source": [
    "columns_list_full=['index', 'Date', 'Location', 'MinTemp', 'MaxTemp', 'Rainfall',\n",
    "       'Evaporation', 'Sunshine', 'WindGustDir', 'WindGustSpeed', 'WindDir9am',\n",
    "       'WindDir3pm', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am',\n",
    "       'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm',\n",
    "       'Temp9am', 'Temp3pm', 'RainToday', 'RISK_MM', 'prediction']\n",
    "df_features = DU\n",
    "df_features = df_features.assign(Features = df_features.Date.astype(str)+\n",
    "                             '@'+df_features.Location.astype(str)+\n",
    "                             '@'+df_features.MinTemp.astype(str)+\n",
    "                             '@'+df_features.MaxTemp.astype(str)+\n",
    "                             '@'+df_features.Rainfall.astype(str)+\n",
    "                             '@'+df_features.Evaporation.astype(str)+\n",
    "                             '@'+df_features.Sunshine.astype(str)+\n",
    "                             '@'+df_features.WindGustDir.astype(str)+\n",
    "                             '@'+df_features.WindGustSpeed.astype(str)+\n",
    "                             '@'+df_features.WindDir9am.astype(str)+\n",
    "                             '@'+df_features.WindDir3pm.astype(str)+\n",
    "                             '@'+df_features.WindSpeed9am.astype(str)+\n",
    "                             '@'+df_features.WindSpeed3pm.astype(str)+\n",
    "                             '@'+df_features.Humidity9am.astype(str)+\n",
    "                             '@'+df_features.Humidity3pm.astype(str)+\n",
    "                             '@'+df_features.Pressure9am.astype(str)+\n",
    "                             '@'+df_features.Pressure3pm.astype(str)+\n",
    "                             '@'+df_features.Cloud9am.astype(str)+\n",
    "                             '@'+df_features.Cloud3pm.astype(str)+\n",
    "                             '@'+df_features.Temp9am.astype(str)+\n",
    "                             '@'+df_features.Temp3pm.astype(str)+\n",
    "                             '@'+df_features.RainToday.astype(str)+\n",
    "                             '@'+df_features.RISK_MM.astype(str))\n",
    "\n",
    "df_ground = DU['prediction']\n",
    "df_features = df_features.drop(columns_list_full, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T22:16:24.351614Z",
     "start_time": "2019-01-28T22:16:21.770985Z"
    }
   },
   "outputs": [],
   "source": [
    "from heuristics_generator.hg_utils import *\n",
    "doc_creation(df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T22:16:31.030102Z",
     "start_time": "2019-01-28T22:16:31.009541Z"
    }
   },
   "outputs": [],
   "source": [
    "global cand_extractor\n",
    "T1, cand_extractor = cand_creation(df_features)\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "rows = session.query(T1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T22:19:47.861663Z",
     "start_time": "2019-01-28T22:19:47.235956Z"
    }
   },
   "outputs": [],
   "source": [
    "train_sents, dev_sents, test_sents, train_ground, val_ground, test_ground = splitting_sets_with_labels(session, cand_extractor, T1, df_ground)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heuristics Generator\n",
    "The system starts with the heuristics generator component which takes the labeled set DL and the unlabeled set DU as inputs and outputs a set of heuristics H of size K denoted as (h1, h2, â€¦hk) and a vector of initial probabilistic labels for the points in DU.\n",
    "The process starts with defining the input (features) for the potential models. Then, the process continues with creating the models (heuristics) and evaluating their performance and coverage. Finally, the process ranks the heuristics generated by each, and every, iteration to decide upon which heuristic to add to the set H."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T22:23:27.847504Z",
     "start_time": "2019-01-28T22:23:27.643505Z"
    }
   },
   "outputs": [],
   "source": [
    "get_ipython().config.get('IPKernelApp', {})['parent_appname'] = \"\"\n",
    "columns_list= ['Date', 'Location', 'MinTemp', 'MaxTemp', 'Rainfall',\n",
    "       'Evaporation', 'Sunshine', 'WindGustDir', 'WindGustSpeed', 'WindDir9am',\n",
    "       'WindDir3pm', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am',\n",
    "       'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm',\n",
    "       'Temp9am', 'Temp3pm', 'RainToday', 'RISK_MM']\n",
    "\n",
    "df_gold_label= prepare_gold_labels(session, T1, DU, columns_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T23:37:41.712101Z",
     "start_time": "2019-01-28T23:37:41.693657Z"
    }
   },
   "source": [
    "When evaluating the performance of the heuristics produced during each iteration, the component also considers the overall coverage of the heuristics when applied to DU. The component aims to widen the range of the data points that receive labels from H in DU. In other words, the goal of the component is to output a set of heuristics that are individually accurate while achieving high labeling coverage when combined. Therefore, to estimate the performance of the heuristics. The performance metrics are computed by applying each heuristic to DL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heuristics_generator.loader import DataLoader\n",
    "dl = DataLoader()\n",
    "train_primitive_matrix, val_primitive_matrix, test_primitive_matrix, \\\n",
    "train_ground, val_ground, test_ground = dl.load_data_tabular(train_sents, test_sents, dev_sents, train_ground, test_ground, val_ground)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from heuristics_generator.verifier import Verifier\n",
    "from heuristics_generator.heuristic_generator import HeuristicGenerator\n",
    "from heuristics_generator.synthesizer import Synthesizer\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "hg = HeuristicGenerator(train_primitive_matrix, val_primitive_matrix, val_ground, train_ground, b=0.5)\n",
    "hg.run_synthesizer(max_cardinality=1, idx=None, keep=6, model='lr')\n",
    "\n",
    "syn = Synthesizer(val_primitive_matrix, val_ground, b=0.5)\n",
    "heuristics, feature_inputs = syn.generate_heuristics('nn', 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verifier = Verifier(hg.L_train, hg.L_val, val_ground, has_snorkel=False)\n",
    "verifier.train_gen_model()\n",
    "verifier.assign_marginals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_idx = verifier.find_vague_points(gamma=0.1,b=0.5)\n",
    "\n",
    "validation_accuracy = []\n",
    "training_accuracy = []\n",
    "validation_coverage = []\n",
    "training_coverage = []\n",
    "training_marginals = []\n",
    "idx = None\n",
    "\n",
    "hg = HeuristicGenerator(train_primitive_matrix, val_primitive_matrix, val_ground, train_ground, b=0.5)\n",
    "for i in range(3,26):\n",
    "    if i == 3:\n",
    "        hg.run_synthesizer(max_cardinality=2, idx=idx, keep=3, model='dt')\n",
    "    else:\n",
    "        hg.run_synthesizer(max_cardinality=2, idx=idx, keep=1, model='dt')\n",
    "    hg.run_verifier()\n",
    "   \n",
    "    va,ta, vc, tc = hg.evaluate()\n",
    "    validation_accuracy.append(va)\n",
    "    training_accuracy.append(ta)\n",
    "    training_marginals.append(hg.vf.train_marginals)\n",
    "    validation_coverage.append(vc)\n",
    "    training_coverage.append(tc)\n",
    "        \n",
    "    hg.find_feedback()\n",
    "    idx = hg.feedback_idx\n",
    "    \n",
    "    if idx == []:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_marginals = training_marginals\n",
    "L_train = hg.L_train\n",
    "\n",
    "from scipy import sparse\n",
    "L_train = L_train.astype(int)\n",
    "L_train= sparse.csr_matrix(L_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, to combine the output of the heuristic and generate an initial vector of probabilistic labels, we employ a generative model to learn the accuracies of the heuristics in H and produce a single probabilistic label for each data point in the unlabeled dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global gen_model \n",
    "gen_model, gen_train_marginals = Fitting_Gen_Model(L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = gen_model.predictions(L_train, batch_size=None)\n",
    "gen_model.learned_lf_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heuristics_generator.hg_utils import *\n",
    "abstain = 0\n",
    "agreements_list=[]\n",
    "for rows in L_train:\n",
    "    if len(rows.data) == 0:\n",
    "        abstain=abstain+1      \n",
    "    agreements_list.append(abs(sum(rows.data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data-driven Active Learner\n",
    "The component tries to integrate the user in the loop at this point by employing active learning. However, our problem settings do not impose traditional active learning scenarios where we usually have a small set of labeled points and a larger set of unlabeled data. Instead, we deal with a set of probabilistic labels that are classified based on the confidence of the generative model. Therefore, we adopt meta-active learning in this component and apply a data-driven approach to learn the query strategy. The approach formulates the process of designing the query strategy as a regression problem. We train a regression model to predict the reduction of the generalization error associated with adding a labeled point {xi, yi} to the training data of a classifier. Our main hypothesis is that this regressor can serve as the query strategy in our problem settings to outperform the baseline strategies since it is customized to the underlying distribution and considers the output of the generative model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "agreements_list=[]\n",
    "unlabeled_list=[]\n",
    "rows = session.query(T1).filter(T1.split==0)\n",
    "for r in rows: \n",
    "    index_list.append(r.Features.sentence.document_id-1),\n",
    "for rows in L_train:\n",
    "    if len(rows.data) == 0:\n",
    "        unlabeled_list.append(True)\n",
    "    else:\n",
    "        unlabeled_list.append(False)\n",
    "    agreements_list.append(abs(sum(rows.data)))\n",
    "    \n",
    "df_with_additional_info = pd.DataFrame(index_list)\n",
    "df_with_additional_info.columns=['index']\n",
    "df_with_additional_info['disagreement_factor'] = agreements_list\n",
    "df_with_additional_info['unlabeled_flag'] = unlabeled_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_additional_info=df_with_additional_info.rename(columns={'index': 'index'})\n",
    "original_data = DU\n",
    "original_data = DU.rename(columns={'Index': 'index'})\n",
    "df_with_additional_info = df_with_additional_info.merge(original_data, on=['index'], how='left', indicator= True)\n",
    "cond1 = df_with_additional_info['unlabeled_flag'] == True\n",
    "cond2 = df_with_additional_info['disagreement_factor'] < 3\n",
    "df_active_learning= df_with_additional_info[cond1 | cond2]\n",
    "print(\"Data with additional info: disagreements and abstain\")\n",
    "print(df_with_additional_info.shape)\n",
    "print(\"Data for Active learning: Data with additional info after applying conditions\")\n",
    "print(df_active_learning.shape)\n",
    "df_active_learning = df_active_learning.drop(['unlabeled_flag', 'disagreement_factor', '_merge'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget_variable=0.7\n",
    "labeling_budget = int(budget_variable*len(df_with_additional_info.index))\n",
    "if(labeling_budget >= df_active_learning.shape[0]):\n",
    "    labeling_budget= int(1*len(df_active_learning.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from data_learner.active_learner import *\n",
    "from data_learner.models import DDL_Dataset \n",
    "from data_learner.lal_model import LALmodel\n",
    "\n",
    "fn = 'LAL-iterativetree-simulatedunbalanced-big.npz'\n",
    "parameters = {'est': 1000, 'depth': 40, 'feat': 6 }\n",
    "filename = '../data_learner/datasets/'+fn\n",
    "regression_data = np.load(filename)\n",
    "regression_features = regression_data['arr_0']\n",
    "regression_labels = regression_data['arr_1']\n",
    "lalModel = RandomForestRegressor(n_estimators = parameters['est'], max_depth = parameters['depth'], \n",
    "                                 max_features=parameters['feat'], oob_score=True, n_jobs=8)\n",
    "lalModel.fit(regression_features, np.ravel(regression_labels))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from data_learner.dl_utils import *\n",
    "indices, labels= run_dll(lalModel, labeling_budget,df_active_learning);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic Labels Generator\n",
    "The final component of Asterisk is the label generator, which aims at learning the accuracies of the generated heuristics using the refined heuristics matrix Hupdated, and then combines all the output of these heuristics to produce a single probabilistic label for each point in DU. This process is accomplished by learning the structure of a generative model Gen which utilizes the refined matrix to model a process of labeling the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL_Results=pd.DataFrame(columns=['index','AL_Label'])\n",
    "AL_Results['index']=alLALiterative.indices.astype('int64')\n",
    "AL_Results['AL_Label']=labels\n",
    "AL_Results = AL_Results.sort_values(by =['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL_Results.loc[AL_Results['AL_Label']==0, 'AL_Label']=-1\n",
    "data_with_AL_Results = df_with_additional_info.merge(AL_Results, on=['index'], how='left')\n",
    "true_label = data_with_AL_Results['AL_Label']\n",
    "true_label = true_label.fillna(0)\n",
    "for i in range(len(true_label)):\n",
    "    if true_label[i] !=0:\n",
    "        L_train[i,:]=true_label[i]\n",
    "gen_model, AL_train_marginals = Fitting_Gen_Model(L_train)\n",
    "predictions = gen_model.predictions(reef_L_train, batch_size=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(predictions, bins=20)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (snorkel)",
   "language": "python",
   "name": "snorkel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
